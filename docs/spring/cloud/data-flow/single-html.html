<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.10">
<title>Spring Cloud Data Flow Documentation</title>
<link rel="stylesheet" href="css/spring.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style type="text/css">
body {
	font-family: 'Malgun Gothic', '맑은 고딕', dotum, '돋움', sans-serif
}
</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3LG0R87MZJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3LG0R87MZJ');
</script>
</head>
<body class="book toc2 toc-left">
<div id="header">
<h1>Spring Cloud Data Flow Documentation</h1>
<div class="details">
<span id="revnumber">version 2.2.0.RELEASE</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#concepts">1. Concepts</a>
<ul class="sectlevel2">
<li><a href="#architecture">1.1. Architecture</a>
<ul class="sectlevel3">
<li><a href="#서버-구성-요소-server-components">1.1.1. 서버 구성 요소 (Server Components)</a>
<ul class="sectlevel4">
<li><a href="#database">Database</a></li>
<li><a href="#security">Security</a></li>
</ul>
</li>
<li><a href="#application-types">1.1.2. Application Types</a>
<ul class="sectlevel4">
<li><a href="#long-lived-applications">Long-lived Applications</a></li>
<li><a href="#short-lived-applications">Short-lived Applications</a></li>
</ul>
</li>
<li><a href="#prebuild-applications">1.1.3. PreBuild Applications</a></li>
<li><a href="#microservice-architectural-style">1.1.4. Microservice Architectural Style</a>
<ul class="sectlevel4">
<li><a href="#comparison-to-other-architectures">Comparison to Other Architectures</a></li>
<li><a href="#streams">Streams</a></li>
<li><a href="#tasks-and-batch-jobs">Tasks and Batch Jobs</a></li>
<li><a href="#composed-tasks-2">Composed Tasks</a></li>
</ul>
</li>
<li><a href="#platforms">1.1.5. Platforms</a></li>
</ul>
</li>
<li><a href="#stream-processing">1.2. Stream Processing</a>
<ul class="sectlevel3">
<li><a href="#messaging-middleware">1.2.1. Messaging Middleware</a></li>
<li><a href="#spring-cloud-stream">1.2.2. Spring Cloud Stream</a></li>
<li><a href="#running-streaming-apps-in-the-cloud">1.2.3. Running Streaming Apps in the Cloud</a></li>
<li><a href="#orchestrating-streaming-apps">1.2.4. Orchestrating Streaming Apps</a></li>
<li><a href="#next-steps">1.2.5. Next Steps</a></li>
</ul>
</li>
<li><a href="#batch-processing">1.3. Batch Processing</a>
<ul class="sectlevel3">
<li><a href="#spring-batch">1.3.1. Spring Batch</a></li>
<li><a href="#running-batch-apps-in-the-cloud">1.3.2. Running Batch Apps in the Cloud</a></li>
<li><a href="#orchestrating-batch-apps">1.3.3. Orchestrating Batch apps</a></li>
<li><a href="#next-steps-2">1.3.4. Next Steps</a></li>
</ul>
</li>
<li><a href="#monitoring">1.4. Monitoring</a></li>
<li><a href="#tooling">1.5. Tooling</a>
<ul class="sectlevel3">
<li><a href="#dashboard">1.5.1. Dashboard</a></li>
<li><a href="#shell">1.5.2. Shell</a></li>
<li><a href="#restful-api">1.5.3. RESTful API</a></li>
<li><a href="#java-client">1.5.4. Java Client</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#stream-developer-guides">2. Stream Developer guides</a>
<ul class="sectlevel2">
<li><a href="#developer-guides">2.1. Developer guides</a></li>
<li><a href="#getting-started">2.2. Getting Started</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="concepts"><a class="anchor" href="#concepts"></a>1. Concepts</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="architecture"><a class="anchor" href="#architecture"></a>1.1. Architecture</h3>
<div class="paragraph">
<p>이 가이드에서는 Data Flow architecture의 주요 개념을 설명합니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Data Flow의 서버 구성 요소</p>
</li>
<li>
<p>server components는 stream과 batch Job을 배포할 수 있는 application type 입니다.</p>
</li>
<li>
<p>배포된 application과 microservice architecture와 DLS을 사용하여 정의하는 방법</p>
</li>
<li>
<p>배포되는 platform</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>가이드의 다른 섹션에서는 아래의 내용을 설명합니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>서버 구성 요소와 보안하는 방법과 서버 구성 요소와 상호 작용하는데 사용되는 도구(Tooling)</p>
</li>
<li>
<p>Streming data pipeline의 실시간 모니터링</p>
</li>
<li>
<p>Stream 과 Batch data pipeline 개발하는데 사용할 수 있는 Spring project</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="서버-구성-요소-server-components"><a class="anchor" href="#서버-구성-요소-server-components"></a>1.1.1. 서버 구성 요소 (Server Components)</h4>
<div class="paragraph">
<p>Data Flow는 2개의 main components를 가지고 있습니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Data Flow Server</p>
</li>
<li>
<p>Skipper Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Data Flow에 접근하는 주요 진입점은 Data Flow Server의 RESTFul API 입니다.<br>
web dashboard는 Data Flow Server에서 제공됩니다.<br>
Data Flow Server와 Data Flow Shell application은 둘다 web API를 통해 통신합니다.</p>
</div>
<div class="paragraph">
<p>서버는 local machine, Cloud Foundry, Kubernetes와 같은 여러 플랫폼에서 실행할 수 있습니다.<br>
각 서버는 관계형 데이터베이스에 상태를 저장합니다.</p>
</div>
<div class="paragraph">
<p>다음 이미지는 아키텍처의 high-level의 보기와 communication 경로를 보여줍니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/arch-overview.webp" alt="arch overview">
</div>
</div>
<div class="paragraph">
<p>Data Flow Server는 다음의 역할을 합니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>DSL(Domain-Specific Language)에 기반하여 Stream과 Batch Job 정의 파싱</p>
</li>
<li>
<p>Stream, Task, Batch Job 정의를 검증하고 지속합니다.</p>
</li>
<li>
<p>jar, docker image와 같은 artifact를 DSL에 사용되는 이름에 등록</p>
</li>
<li>
<p>배치 작업을 하나 이상의 플랫폼에 배치</p>
</li>
<li>
<p>플랫폼에 작업 스케줄링 위임</p>
</li>
<li>
<p>자세한 작업 및 배치 작업 실행 기록을 쿼리</p>
</li>
<li>
<p>메시징 입력 및 출력을 ㅡ구성하고 배포 등록 정보 (예: 초기 인스턴스 수, 메모리 요구 사항 및 데이터 분할)를 전달하는 구성 등록 정보를 Streams에 추가</p>
</li>
<li>
<p>Skipper에 Stream 배포 위임</p>
</li>
<li>
<p>감사 작업 (예: Stream 만들기, 배포, 배포 취소 및 일괄 생성, 실행 삭제)</p>
</li>
<li>
<p>Stream, Batch Job DSL 탭 완성 기능 제공</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Skipper Server는 다음의 역할을 합니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Stream을 하나이상의 플랫폼에 배포</p>
</li>
<li>
<p>blue/green 업데이트 전략에 기반한 상태 시스템을 사용하여 하나 이상의 플랫폼에서  Stream을 upgrade하고 rolling back</p>
</li>
<li>
<p>각 Stream의 manifest file(어떤 application이 배포되었는지에 대한 final description을 보여줌)의 히스토리 저장</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="database"><a class="anchor" href="#database"></a>Database</h5>
<div class="paragraph">
<p>Data Flow Server와 Skipper Server는 RDBMS가 필요합니다.<br>
기본 설정은 H2 내장 Database를 사용합니다.<br>
외부 database를 사용하도록 서버를 구성할 수 있습니다.<br>
지원되는 database는 H2, HSQLDB, MySQL, Oracle, PostgreSQL, DB2 및 SqlServer 입니다.<br>
각 서버가 시작할 때 schema가 자동으로 생성됩니다.</p>
</div>
</div>
<div class="sect4">
<h5 id="security"><a class="anchor" href="#security"></a>Security</h5>
<div class="paragraph">
<p>Data Flow와 SkipperServer는 OAuth 2.0 인증을 사용하여 관련 Rest endpoint를 보호합니다.<br>
기본 인증을 사용하거나 OAuth2 access token을 사용하여 access 할 수 있습니다.<br>
OAuth 공급자의 경우 포괄적인 LDAP 지원을 제공하는 CloudFoundry 사용자 계정 및 인증 (UAA) 서버를 사용하는 것이 좋습니다.<br>
필요에 따라 보안 기능을 구성하는 방법에 대한 자세한 내용은 reference guide의 Security Section을 참조하세요.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
기본 설정의 경우 Rest endpoint(adminitration, management, health)와 Dashboard UI는 인증된 access 가 필요하지 않습니다.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect3">
<h4 id="application-types"><a class="anchor" href="#application-types"></a>1.1.2. Application Types</h4>
<div class="paragraph">
<p>application은 두가지 형태가 있습니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Long-lived applications. 2가지 타입의 long-lived application이 있습니다.</p>
<div class="ulist">
<ul>
<li>
<p>단일 input 또는 output을 통해 무제한의 data가 소비되거나 생성되는 Message-driven application</p>
</li>
<li>
<p>다중 input, output을 가질 수 있는 Message-driven application. 또는 messaging middleware를 전혀 사용하지 않는 응용 프로그램</p>
</li>
</ul>
</div>
</li>
<li>
<p>Short-lived applications은 유한한 data 집합을 처리한 다음 종료합니다. 두가지 변형이 있습니다.</p>
<div class="ulist">
<ul>
<li>
<p>code를 실행하고 Data Flow database에 실행 상태를 저장하는 형태. 선택적으로 Spring Cloud Task framework를 사용할 수 있고 java application일 필요는 없습니다. 그러나 응용 프로그램은 Data Flow의 database에 실행 상태를 저장해야 합니다.</p>
</li>
<li>
<p>batch processing에 수행을 기반하여 Spring Batch framework를 포함한 첫 번째의 확장</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Spring Cloud Stream framework 및 Spring Cloud Task 또는 Spring Batch framework를 기반으로 하는 Short-lived application을 기반으로 Long-lived application을 작성하는 것이 일반적입니다.<br>
Documentation에는 data pipeline을 개발할 때 이러한 framework를 사용하는 방법을 보여주는 guide가 많이 있습니다.<br>
그러나 Spring을 사용하지 않는 long-lived, short-lived application을 작성할 수도 있습니다.<br>
또한 다른 프로그래밍 언어로도 작성할 수도 있습니다.</p>
</div>
<div class="paragraph">
<p>runtime 에 따라 두가지 방법으로 application을 package 할 수 있습니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Maven repository, file location 또는 Http를 통해 액세스 할 수 있는 Spring Boot uber-jar</p>
</li>
<li>
<p>Docker registroy에서 호스팅되는 Docker image</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="long-lived-applications"><a class="anchor" href="#long-lived-applications"></a>Long-lived Applications</h5>
<div class="paragraph">
<p>Long-lived Applications은 계속해서 실행되어야 합니다.<br>
만약 application이 중지되면 platform이 다시 시작할 수 있어야 합니다.</p>
</div>
<div class="paragraph">
<p>Spring Cloud Stream framework는 공통 message system에 연결된 message-driven microservice application의 작성을 단순화하는 프로그래밍 모델을 제공합니다.<br>
명확한 미들웨어에 불가지론적인 핵심 비즈니스 로직을 작성할 수 있습니다 (? You can write core business logic that is agnostic to the specific middleware.)<br>
미들웨어는 application에 대한 Spring Cloud Stream Binder 라이브러리의 dependency를 추가하여 사용할 수 있습니다.<br>
다음과 같은 messaging middleware 제품에 대한 binding library가 있습니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>RabbitMQ</p>
</li>
<li>
<p>Kafka</p>
</li>
<li>
<p>Kafka Streams</p>
</li>
<li>
<p>Amazon Kinesis</p>
</li>
<li>
<p>Google Pub/Sub</p>
</li>
<li>
<p>Solace PubSub+</p>
</li>
<li>
<p>Azure Event Hubs</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Data Flow Server 는 long-lived application을 배포하기 위해 Skipper server에 위임합니다.
</td>
</tr>
</table>
</div>
<div class="sect5">
<h6 id="streams-with-sources-processors-and-sinks"><a class="anchor" href="#streams-with-sources-processors-and-sinks"></a>Streams with Sources, Processors and Sinks</h6>
<div class="paragraph">
<p>Spring Cloud Stream은 코드에서 message exchange pattern즉 application의 input과 output을 캡슐화하는 binding interface의 개념을 정의합니다.<br>
Spring Cloud Stream은 다음과 같은 common message exchange 계약에 해당하는 몇가지 binding interface를 제공합니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Source : 대상에 message를 보내는 message producer</p>
</li>
<li>
<p>Sink : 대상에서 message를 읽는 message consumer</p>
</li>
<li>
<p>Processor : Source와 Sink의 조합. processor는 대상에서 message를 소비하고 다른 대상으로 보낼 message를 생성합니다.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Data Flow는 등록된 application의 type을 설명하기 위해 source, processor, sink를 사용하여 사용하여 등록합니다.</p>
</div>
<div class="paragraph">
<p>다음 예제는 http source(HTTP 요청을 수신 대기하고 HTTP payload 대상으로 보내는 application)와 log sink 를 등록하기 위한 shell 구문을 보여줍니다.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="bash" class="language-bash hljs">dataflow:&gt;app register --name http --type source --uri maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE
Successfully registered application 'source:http'

dataflow:&gt;app register --name log --type sink --uri maven://org.springframework.cloud.stream.app:log-sink-rabbit:1.1.0.RELEASE
Successfully registered application 'sink:log'</code></pre>
</div>
</div>
<div class="paragraph">
<p>http와 log를 Data Flow에 등록하면  다음과 같이 pipes와 filters 구문을 사용한 Stream Pipeline DSL을 사용하여 stream 정의를 생성할 수 있습니다.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="bash" class="language-bash hljs">dataflow:&gt;stream create --name httpStream --definition "http | log"</code></pre>
</div>
</div>
<div class="paragraph">
<p>http | log의 pipe 기호는 source의 output을 sink의 input으로 연결을 나타냅니다.<br>
Data Flow는 stream을 배포할 때 적절한 properties를 설정하여 messaging middleware를 통해 source가 sink와 연결할 수 있게 합니다.</p>
</div>
</div>
<div class="sect5">
<h6 id="streams-with-multiple-inputs-and-outputs"><a class="anchor" href="#streams-with-multiple-inputs-and-outputs"></a>Streams with Multiple Inputs and Outputs</h6>
<div class="paragraph">
<p>Sources, Sink 및 Processors는 모두 단일 output, 단일 input, 또는 둘다 있습니다.<br>
이 것이 Data Flow가 output 대상을 input 대상과 짝을 이뤄 application property를 설정하게 합니다.<br>
하지만 message processing application은 한개 이상의 input과 output 대상이 있을 수 있습니다.<br>
Spring Cloud Stream은 custom binding interface를 정의할 수 있도록 지원합니다.</p>
</div>
<div class="paragraph">
<p>multiple input을 가진 application을 포함한 stream을 정의하려면 source, sink, processor 타입 대신 app 타입을 사용해야 합니다.<br>
stream 정의는 single pipe 기호(|)를 대신 double pipe 기호(||)를 사용합니다. Stream Application DSL을 사용합니다.<br>
||는 application 간 암묵적인 연결 없이 병렬을 의미한다고 생각하십시요.</p>
</div>
<div class="paragraph">
<p>다음 예제에서는 가상의 'orderStream&#8217;을 보여줍니다.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="bash" class="language-bash hljs">dataflow:&gt;stream create --definition "orderGeneratorApp || baristarApp || hotDrinkDeliveryApp || coldDrinkDeliveryApp" -- name orderStream</code></pre>
</div>
</div>
<div class="paragraph">
<p>| 기호로 정의했을 때는 하나의 output은 항상 하나의 input과 쌍을 이루기 때문에Data Flow는 DSL을 사용하여 인접한 application과 통신하도록 stream에서 각 application을 설정할 수 있습니다.<br>
|| 기호를 사용할 때는 여러 output 및 input 대상을 쌍으로 구성하는 configuration properties를 제공해야 합니다.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Stream ApplicationDSL을 사용하고 messaging middleware를 사용하지 않는 application을 배포하여 single application으로 stream을 만들 수 있습니다.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>이 예제는 long-lived application 유형에 대한 일반적인 의미를 제공합니다.<br>
추가적인 guide는 long-lived application을 개발, 테스트 및 등록하는 방법과 배포하는 방법에 대해 자세히 설명합니다</p>
</div>
<div class="paragraph">
<p>다음 주요 섹션에서는 배포된 stream의 runtime architecture에 대해 설명합니다.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="short-lived-applications"><a class="anchor" href="#short-lived-applications"></a>Short-lived Applications</h5>
<div class="paragraph">
<p>Short-lived application은 일정 기간 (수분에서 수시간) 실행된 다음 종료됩니다.<br>
일정(예: 매주 평일 오후 6시에 실행)이나 이벤트(예: FTP 서버에 파일이 생성된 경우)에 따라 실행될 수 있습니다.</p>
</div>
<div class="paragraph">
<p>Spring cloud Task framework는 short-lived application의 life cycle event(예: 시작 시간, 종료 시간 및 종료 코드)를 기록하는 show-lived microservice을 개발할 수 있게 합니다.</p>
</div>
<div class="paragraph">
<p>task application은 application의 type을 설명하는 task라는 이름으로 Data Flow 에 등록됩니다.</p>
</div>
<div class="paragraph">
<p>다음 예는 timestamp task(현재 시간을 출력하고 종료하는 application)를 등록하는 shell 구문입니다.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="bash" class="language-bash hljs">dataflow:&gt;app register --name timestamp --type task --uri maven://org.springframework.cloud.task.app:timestamp-task:1.3.0.RELEASE</code></pre>
</div>
</div>
<div class="paragraph">
<p>task 정의는 다음 예제와 같이 task의 이름을 참조하여 작성됩니다.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="bash" class="language-bash hljs">dataflow:&gt;task create tsTask --definition "timestamp"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Spring Batch framework는 아마 short-lived application을 작성하는 Spring 개발자들에게 떠오르는 것일 겁니다.<br>
Spring Batch는 Spring Cloud Task보다 훨씬 풍부한 기능 set을 제공하며 대량의 데이터를 처리할 때 권장됩니다.<br>
사용 사례는 많은 CSV 파일을 읽고 각 데이터 행을 변환하고 각 변환된 행을 database에 저장하하는 것입니다.<br>
Spring Batch는 Spring Batch job의 실행에 대한 훨씬 더 풍부한 정보 set과 함께 자체 database schema를 제공합니다<br>
Spring Cloud Task는 Spring Batch와 통합되어 Spring Cloud Task applicatino이 Spring Batch Job을 정의하면 Spring Cloud Task와 Spring Cloud Batch 실행 테이블 사이의 링크가 생성됩니다.</p>
</div>
<div class="paragraph">
<p>Spring Batch를 사용하는 task는 이전과 같은 방법으로 등록 및 생성됩니다.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Spring Cloud Data Flow 서버는 작업을 platform으로 시작합니다.
</td>
</tr>
</table>
</div>
<div class="sect5">
<h6 id="composed-tasks"><a class="anchor" href="#composed-tasks"></a>Composed Tasks</h6>
<div class="paragraph">
<p>Spring Cloud Data Flow는 graph의 각 노드가 task application인 directed graph를 작성할 수 있게 합니다.</p>
</div>
<div class="paragraph">
<p>이것은 composed task에 대해 Composed Task Domain Specific Language 를 사용하여 수행됩니다.<br>
Composed Task DSL에는 전체 흐름을 결정하는 여러 기호가 있습니다.<br>
다음 예제에서는 이중 앰퍼센드 기호 (&amp;&amp;)를 조건부 실행에 사용하는 방법을 보여줍니다.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code data-lang="bash" class="language-bash hljs">dataflow:&gt;task create simpleComposedTask --definition "task1 &amp;&amp; task2"</code></pre>
</div>
</div>
<div class="paragraph">
<p>DSL 표현식 (task1 &amp;&amp; task2) 는 task1이 성공적으로 진행된 경우에만 task2가 실행된다는 것을 의미합니다.<br>
task의 graph는 Composed Task Runner라는 task application을 통해 실행됩니다.</p>
</div>
<div class="paragraph">
<p>추가적인 guide는 short-lived application을 개발, 테스트 및 등록하는 방법과 배포하는 방법에 대해 자세히 설명합니다.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="prebuild-applications"><a class="anchor" href="#prebuild-applications"></a>1.1.3. PreBuild Applications</h4>
<div class="paragraph">
<p>개발을 시작하려면 많은 사전 구축된 application을 사용하여 일반적인 data source 및 sink와 통합할 수 있습니다.<br>
예를 들어 cassandra data를 쓰는 cassandra sink와 groovy script를 사용하여 들어오는 data를 변환하는 processor를 사용할 수 있습니다</p>
</div>
<div class="paragraph">
<p>installation instruction은 이러한 applicatino을 Spring Cloud Data Flow에 등록하는 방법을 보여줍니다.</p>
</div>
</div>
<div class="sect3">
<h4 id="microservice-architectural-style"><a class="anchor" href="#microservice-architectural-style"></a>1.1.4. Microservice Architectural Style</h4>
<div class="paragraph">
<p>Data Flow와 Skipper server는 각각 자신의 프로세스에서 실행되는 microservice application의 모음으로 플랫폼에 Stream 및 Composed Batch Job을 배포합니다.<br>
각 microservice application은 다른 application과 독립적으로 scale up또는 scale down 할 수 있으며 각 application마다 고유한 versioning lifecycle이 있습니다.<br>
Skipper는 런타임에 stream의 각 application을 개별적으로 업그레이드하거나 롤백할 수 있습니다.</p>
</div>
<div class="paragraph">
<p>Spring Cloud Stream과 Spring Cloud Task를 사용할 때 각 microservice application은 기본 라이브러리로서 Spring Boot를 기반으로 구축됩니다.<br>
따라서 health check, security, configurable logging, monitoring 및 관리 기능 뿐만 아니라 executable jar packaging과 같은 모든 microservice application 기능이 제공됩니다.</p>
</div>
<div class="paragraph">
<p>이러한 microservice application은 java -jar 에 적절한 구성 속성을 사용하고 전달하여 스스로 실행할 수 있는 단순한 applicatinon임을 강조하는 것이 중요합니다.<br>
데이터 처리를 위해 microservice application을 만드는 것은 다른 Spring Boot Applicatino을 만드는 것과 비슷합니다.<br>
Spring Initializer 웹사이트를 사용하여 Stream 기반 또는 Task 기반 microservice의 기본 scaffolding을 만들 수 있습니다.</p>
</div>
<div class="paragraph">
<p>Data Flow 및 Skipper server는 각 applicatino에 적절한 application properties를 전달하는 것 외에도 대상 플랫폼의 infrastructure를 준비해야 합니다.<br>
예를 들어 Cloud Foundry에서는 지정된 service를 applicatino에 binding합니다. Kubernetes의 경우 배포 및 service resource가 생성됩니다.</p>
</div>
<div class="paragraph">
<p>Data Flow Server는 대상 건타임에 여러 관련 application을 간단하게 배포하고 필요한 input, output 항목, 파티션 및 metric 기능을 설정하는데 유용합니다.<br>
그러나 각 microservice application을 수동으로 배포하고 Data Flow나 Skipper를 사용하지 않을 수도 있습니다.<br>
이 방법은 소규모 배포를 시작할 때 더 많은 application을 개발할 때 Data Flow의 편리성과 일관성을 점진적으로 채택하는 것이 더 적절할 수 있습니다.<br>
Stream 및 Task 기반 microservice를 수동으로 배포하는 것도 Data Flow server가 제공하는 자동화된 application 설정과 플랫폼 대상 지정 단계를 더 잘 이해하는데 도움이 되는 유용한 교육 방법입니다.<br>
stream 및 Batch 개발자 guide는 이 방법을 따릅니다.</p>
</div>
<div class="sect4">
<h5 id="comparison-to-other-architectures"><a class="anchor" href="#comparison-to-other-architectures"></a>Comparison to Other Architectures</h5>
<div class="paragraph">
<p>Spring Cloud Data Flow의 architectural type은 다른 Stream 과 Batch processing platform과 다릅니다.<br>
예를 들어 Apache Spark, Apache Flink 및 Google Cloud Dataflow 에서 application은 전용 comopute engine cluster에서 실행됩니다.<br>
computing engine 특성 상 이러한 플랫폼은 Spring cloud Data Flow와 비교하여 복잡한 계산을 수행하기 위한 보다 풍부한 환경을 제공하지만 데이터 중심 application을 생성 할 때 종종 필요하지 않은 다른 실행 환경의 복잡성을 초래합니다.<br>
그렇다고 Sprnig Cloud Data Flow를 사용할 때 실시간 데이터 계산을 할 수 없다는 것을 의미하지는 않습니다.<br>
예를 들어 kafka Streams API를 사용하는 application을 개발하면 time-sliding-window와 moving-average 기능 뿐만 아니라 들어오는 메시지와 참조 데이터 집합의 조인이 가능합니다.</p>
</div>
<div class="paragraph">
<p>이 접근 방식의 이점은 인기있는 플랫폼을 실행 런타임으로 위임할 수 있다는 것입니다.<br>
Data Flow는 해당 기능 집합 (resilience, scalability)뿐만 아니라 이미 다른 플랫폼에서 사용하고 있는 지식을 활용할 수 있습니다.<br>
따라서 다른 end-user / web application을 배포하는데 사용되는 것과 동일한 기술을 적용할 수 있으므로 데이터 중심 application을 만들고 관리할 때 인식 격차가 줄어듭니다.</p>
</div>
</div>
<div class="sect4">
<h5 id="streams"><a class="anchor" href="#streams"></a>Streams</h5>
<div class="paragraph">
<p>다음 이미지는 간단한 Stream의 runtime architecture를 보여줍니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/arch-stream-dsl.webp" alt="arch stream dsl">
</div>
</div>
<div class="paragraph">
<p>Stream DSL은 POST로 Data Flow Server에 보내집니다.<br>
Maven 및 Docker atifact에 대한 DSL application 이름 매핑을 기반으로 http source와 jdbc sink application이 Skipper에 의해 대상 플랫폼에 배포됩니다.<br>
HTTP application에 post된 데이터는 database에 저장됩니다.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
http source 및 jdbc sink application은 지정된 플랫폼에서 실행되며 Data Flow나 Skipper server에 어떤 연관도 없습니다.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>다중 input 과 output을 가질 수 있는 application으로 구성된 stream의 runtime architecture는 아래와 같습니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/arch-app-dsl.webp" alt="arch app dsl">
</div>
</div>
<div class="paragraph">
<p>source, sink 또는 processor application을 사용할 때와 동일한 구조입니다.<br>
이 architecture를 정의하기 위한 Stream application DSL은 단일 파이프 기호(|) 대신 이중 파이프 기호(||)를 사용합니다.<br>
또한 이 Stream을 배포할 때 messaging system을 사용하여 각 application을 다른 application에 연결하는 방법을 설명하는 더 많은 정보를 제공해야 합니다.</p>
</div>
</div>
<div class="sect4">
<h5 id="tasks-and-batch-jobs"><a class="anchor" href="#tasks-and-batch-jobs"></a>Tasks and Batch Jobs</h5>
<div class="paragraph">
<p>다음 이미지는 Task와 Spring Batch Job의 runtime architecure를 보여줍니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/arch-batch-dsl.webp" alt="arch batch dsl">
</div>
</div>
</div>
<div class="sect4">
<h5 id="composed-tasks-2"><a class="anchor" href="#composed-tasks-2"></a>Composed Tasks</h5>
<div class="paragraph">
<p>다음 이미지는 composed task의 runtime architecture를 보여줍니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/arch-composed-task-dsl.webp" alt="arch composed task dsl">
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="platforms"><a class="anchor" href="#platforms"></a>1.1.5. Platforms</h4>
<div class="paragraph">
<p>Spring Foundry, Kubernetes 및 local Machine에 Spring Cloud Data Flow server와 Skipper server를 배포할 수 있습니다.</p>
</div>
<div class="paragraph">
<p>또한 이러한 서버에 의해 배포된 application을 여러 플랫폼에 배포할 수도 있습니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Local: local machine, Cloud Foundry 또는 Kubernetes에 배포할 수 있습니다.</p>
</li>
<li>
<p>Cloud Foundry: Cloud Foundry 또는 Kubernetes에 배포할 수 있습니다.</p>
</li>
<li>
<p>Kubernetes: Kubernetes 또는 Cloud Foundry에 또는 배포할 수 있습니다.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>가장 일반적인 architecture는 application을 배포하는 동안 여러 Cloud Foundry 조직, 공간 및 기판과 여러 Kubernetes cluster에 배포할 수 있습니다.</p>
</div>
<div class="paragraph">
<p>HashiCorp, Nomad, Red Hat OpenShift 및 Apache Mesos와 같은 다른 플랫폼에 배포할 수 있는 커뮤니티 구현이 있습니다.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
로컬 서버는 Spring Batch admin project를 대신하여 Task 배포를 위해 production 환경에서 지원됩니다.<br>
Strem 배포를 위해  production에서 로컬 서버가 지원되지 않습니다.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="stream-processing"><a class="anchor" href="#stream-processing"></a>1.2. Stream Processing</h3>
<div class="paragraph">
<p>Stream processing은 상호 작용이나 중단없이 무한한 양의 데이터를 처리하는 것으로 정의됩니다.<br>
Stream processing 사용 사례로 실시간 신용카드 사기 탐지 또는 예측 분석이 있습니다.</p>
</div>
<div class="paragraph">
<p>Data Flow의 Stream processing는 구조적으로 RabbitMQ 또는 Apache Kafka와 같은 messaging middleware를 사용하여 연결하는 독립적인 이벤트 기반 streaming application 모음으로 구현됩니다.<br>
application collection은 streaming data pipeline이라고 합니다.<br>
pipeline은 application 간 data flow에 따라 선형 또는 비선형일 수 있습니다.</p>
</div>
<div class="sect3">
<h4 id="messaging-middleware"><a class="anchor" href="#messaging-middleware"></a>1.2.1. Messaging Middleware</h4>
<div class="paragraph">
<p>배포된 stream application은 messaging middleware product를 통해 통신합니다.<br>
RabbitMQ 또는 Kafka를 통해 통신하고 다양한 data 제품과 통합하는데 사용할 수 있는 사전 제작된 stream application을 제공합니다.</p>
</div>
<div class="paragraph">
<p>다음 messaging middleware 제품도 지원합니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kafka Streams</p>
</li>
<li>
<p>Amazon Kinesis</p>
</li>
<li>
<p>Google Pub/Sub</p>
</li>
<li>
<p>Solace PubSub+</p>
</li>
<li>
<p>Azure Event Hubs</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>사용할 middleware는 application에 대한 종속성으로 Spring Cloud Stream Binder 라이브러리를 추가함으로써 결정됩니다.</p>
</div>
</div>
<div class="sect3">
<h4 id="spring-cloud-stream"><a class="anchor" href="#spring-cloud-stream"></a>1.2.2. Spring Cloud Stream</h4>
<div class="paragraph">
<p>Spring 개발자에게는 Spring Cloud Stream framework를 사용하여 Stream application을 작성하는 것이 좋습니다.<br>
Spring Cloud Stream을 사용하면 공유 messaging system과 연결된 확장성이 뛰어난 event-driven microservice를 쉽게 구축할 수 있습니다.</p>
</div>
<div class="paragraph">
<p>개발자로서 Spring Cloud Stream에 message broker와 함께 기본 API 복잡성 및 연결 보일러 플레이트를 위임하면서 application의 비즈니스 로직 개발에 집중할 수 있습니다.</p>
</div>
<div class="paragraph">
<p>높은 수준에서 streaming application은 messaging middlewar를 통해 이벤트를 생성하거나 소비할 수 있습니다.</p>
</div>
</div>
<div class="sect3">
<h4 id="running-streaming-apps-in-the-cloud"><a class="anchor" href="#running-streaming-apps-in-the-cloud"></a>1.2.3. Running Streaming Apps in the Cloud</h4>
<div class="paragraph">
<p>Cloud Foundry와 Kubernetes는 플랫폼에서 long-lived application을 실행하는 컨셉을 지원합니다.<br>
Cloud Foundry는 각각을 Long Running Process (LRP)라고 부릅니다.<br>
kubernetes에서는 batch resource를 사용할 수 있으며 이는 Batch의 지정된 수를 유지하여 application을 실행하는 replica set을 관리합니다.</p>
</div>
<div class="paragraph">
<p>streaming application을 작성할 때 Spring Cloud Stream은  life를 단순화 할 수 있지만 독립적인 Spring Cloud Streaming application 모음이 배포되기 위해선 다음이 필요합니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>모든 applicatino의 input과 output 대상을 설정해야합니다.</p>
</li>
<li>
<p>대상에서 경쟁하는 consumer가 있을 수 있도록 공유된 consumer group property의 공통 name을 구성합니다.</p>
</li>
<li>
<p>모니터링 목적으로 application을 식별하고 metric 정보를 publishing 할 수 있는 몇가지 properties를 구성합니다.</p>
</li>
<li>
<p>messaging middleware에 대한 연결을 구성합니다.</p>
</li>
<li>
<p>application을 실행하는데 필요한 platform을 생성합니다.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Spring Cloud Data Flow를 사용하여 stream을 배포하면 모든 설정 task를 처리하고 대상 플랫폼에서 application을 실행하는데 필요한 플랫폼 resource를 작성합니다.<br>
다양한 배포 properties를 사용하여 배포를 사용자 정의 할 수 있습니다. (예: 메모리 리소스, Cloud Foundry의 buildpack 과 같은 플랫폼 별 속성 또는 kubernetes 배포시 label 설정 같은 공통 속성 설정)</p>
</div>
</div>
<div class="sect3">
<h4 id="orchestrating-streaming-apps"><a class="anchor" href="#orchestrating-streaming-apps"></a>1.2.4. Orchestrating Streaming Apps</h4>
<div class="imageblock">
<div class="content">
<img src="./images/SCDF-stream-orchestration.webp" alt="SCDF stream orchestration">
</div>
</div>
<div class="paragraph">
<p>Spring Cloud Stream을 사용하여 stream application을 작성하거나 미리 만들어진 많은 Spring Cloud Stream application 중 하나를 사용하면 어떻게 streaming data pipeline을 구성하는 application을 정의하고 모든 application의 launcing을 조정할 수 있습니까?<br>
Spring Cloud Data Flow가 도움이 될 수 있는 곳입니다.</p>
</div>
<div class="paragraph">
<p>Spring Cloud Data Flow를 사용하면 drag-and-drop 디자이너를 사용하거나 익숙한 pipe 및 filter 구문과 함께 text 기반 Domain Specific language를 사용하여 stream을 정의할 수 있습니다.<br>
자세한 내용은 Tooling guide를 참조하세요.</p>
</div>
<div class="paragraph">
<p>그런 다음 Kubernetes 또는 Cloud Foundry에 배포할 수 있습니다.<br>
배포가 완료되면 개별 application을 업데이트 해야하므로 Spring Cloud Data Flow는 플랫폼에서 청색/녹색 배치를 트리거하는 간단한 업그레이드 명령을 제공하여 이를 용이하게 합니다.<br>
자세한 내용은 Continuous Delivery guide를 참조하세요.</p>
</div>
<div class="paragraph">
<p>널리 사용되는 다양한 모니터링 시스템을 사용하여 stream을 모니터링 할 수 있으며 Prometheus 및 InfluxDB를 시연합니다.<br>
그런 다음 제공된 grafana dashboard template으로 stream을 볼 수 있습니다.<br>
자세한 내용은 Monitoring을 참조하세요.</p>
</div>
</div>
<div class="sect3">
<h4 id="next-steps"><a class="anchor" href="#next-steps"></a>1.2.5. Next Steps</h4>
<div class="paragraph">
<p>사전 구축된 application을 사용하여 streaming data pipeline을 만드는데 관심이 있다면 Stream Getting Started Guide를 참조하세요.</p>
</div>
<div class="paragraph">
<p>Spring Cloud Stream을 사용하여 사용자 정의 stream processing application을 작성하고 배포하는데 관심이 있다면 Stream Developer Guilde를 참조하세요.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="batch-processing"><a class="anchor" href="#batch-processing"></a>1.3. Batch Processing</h3>
<div class="paragraph">
<p>Batch processing은 상호 작용이나 중단 없이 한정된 양의 데이터를 처리하는 것으로 정의됩니다.<br>
Batch processing을 구현하는 application은 일시적 또는 수명이 짧은(short-lived) application이라고 합니다.<br>
Batch processing의 예로는 billing application이 있습니다.<br>
다음 이미지는 이러한 application을 보여줍니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/batch-app-flow.webp" alt="batch app flow">
</div>
</div>
<div class="paragraph">
<p>이 application은 야간에 실행되어 flat file에서 고객 사용데이터를 읽고 해당 레코드에 대한 가격 정보를 생성한 다음 결제 정보를 결제 테이블에 insert 합니다.<br>
모든 사용자 데이터가 읽혀지고 가격이 책정되고 결제 테이블에 insert되면 application이 중지됩니다.</p>
</div>
<div class="paragraph">
<p>꽤 간단하게 들릴지 모르지만 database에서 table 공간이 부족하여 application이 4시간에서 6시간 실행에 실패하면 어떻게 되는지 생각해야 합니다.<br>
일단 테이블 공간이 추가되면 처음부터 다시 시작하지 않아도 됩니다.<br>
따라서 billing application이 중지된 곳에서 부터 다시 시작할 수 있어야 합니다.</p>
</div>
<div class="sect3">
<h4 id="spring-batch"><a class="anchor" href="#spring-batch"></a>1.3.1. Spring Batch</h4>
<div class="paragraph">
<p>이전 섹션에서는 batch billing application의 최소 요구사항을 설명했습니다<br>
.그러나 우리는 재시작 가능성 기능, reader와 writer를 코딩하기 전에 Spring Batch를 살펴보아야 합니다.<br>
Spring Batch는 로깅 및 추적, 트랜잭션 관리, 작업 처리 통계, 작업 다시 시작, 건너뛰기 및 자원 관리를 포함하여 많은 양의 레코드를 처리하는데 필수적인 재사용 가능한 기능을 제공합니다.<br>
Spring Batch는 Batch Job 재시작 가능성을 처리하고 FlatFileItemReader와 JdbcBatchItemWriter를 제공하므로 이러한 상용구 코드(boilerplate code)를 작성할 필요가 없습니다.<br>
이렇게 하면 데이터를 이용해 가격을 책정하는 비즈니스 로직에 집중할 수 있습니다.</p>
</div>
</div>
<div class="sect3">
<h4 id="running-batch-apps-in-the-cloud"><a class="anchor" href="#running-batch-apps-in-the-cloud"></a>1.3.2. Running Batch Apps in the Cloud</h4>
<div class="paragraph">
<p>Spring Batch가 batch application을 작성할 때 우리의 삶을 단순화 하는 방법을 알 수 있습니다.<br>
하지만 어떻게 cloud에서 batch application을 실행할 수 있을까요?<br>
Cloud Foundry와 Kubernetes는 플랫폼에서 short-lived app을 실행하는 개념을 지원합니다.<br>
Cloud Foundry는 일시적인 앱을 task로 지칭하며 kubernetes는 job으로 간주합니다.<br>
그러나 cloud에서 일시적인 앱을 실행하려면 몇 가지 기본 기능이 필요합니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>application이 시작되고 중지 될 때 기록</p>
</li>
<li>
<p>application의 종료 코드를 기록</p>
</li>
<li>
<p>application에서 리턴된 종료 메시지 또는 오류 메시지 기록</p>
</li>
<li>
<p>이미 실행 중인 application이 실행되지 않도록 하는 기능 필요</p>
</li>
<li>
<p>application이 특정 처리 단계에 도달했음을 다른 application에 알리는 기능 필요</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>이것은 많은 일처럼 들리지만 Spring Cloud Tasks는 더 많은 일을 합니다.<br>
Spring Cloud Task를 사용하면 local또는 cloud에서 short-lived microservice를 개발하고 실행할 수 있습니다.<br>
@EnableTask annotation을 추가하기만 하면 됩니다.</p>
</div>
</div>
<div class="sect3">
<h4 id="orchestrating-batch-apps"><a class="anchor" href="#orchestrating-batch-apps"></a>1.3.3. Orchestrating Batch apps</h4>
<div class="paragraph">
<p>다음 이미지는 Data Flow Server가 여러 cloud의 application을 관리하는 방법을 보여줍니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/SCDF-task-orchestration.webp" alt="SCDF task orchestration">
</div>
</div>
<div class="paragraph">
<p>Spring Batch와 Spring Cloud Task로 batch application을 작성하나 후에는 어떻게 application의 launching을 조절할 수 있을까요?<br>
Spring Cloud Data Flow가 도움이 될 수 있는 지점입니다.<br>
Spring Cloud Data Flow를 사용하면 ad-hoc request이나 batch-job scheduler를 통해 batch application을 시작할 수 있습니다.<br>
또한 다음 플랫폼에서 batch application을 시작할 수 있습니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cloud Foundry</p>
</li>
<li>
<p>Kubernetes</p>
</li>
<li>
<p>Local server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Spring Cloud Data Flow를 사용하면 UI, RESTful api 또는 Spring Cloud Data Flow Shell을 통해 batch application의 실행을 시작하거나 예약할 수 있습니다.</p>
</div>
</div>
<div class="sect3">
<h4 id="next-steps-2"><a class="anchor" href="#next-steps-2"></a>1.3.4. Next Steps</h4>
<div class="paragraph">
<p>미리 작성된 application을 사용하여 batch processing data pipeline을 만드는 방법에 대한 자세한 내용은 Batch Getting Started Guild를 참조하세요.</p>
</div>
<div class="paragraph">
<p>첫 번째 custom batch processing을 작성하고 배포하는데 관심이 있는 경우 Batch Developer Guildes를 참조하세요.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="monitoring"><a class="anchor" href="#monitoring"></a>1.4. Monitoring</h3>
<div class="paragraph">
<p>Data Flow metrics architecture는 vendor-neutral application metrics facade인 Micrometer library를 중심으로 설계되었습니다.<br>
가장 널리 사용되는 모니터링 시스템의  instrumentation client를 통해 간단한  facade를 제공합니다.<br>
micrometer instrumentation library는 Spring Boot에서 application metric의 전달을 강화하고 배포된 stream을 모니터링 하는데 중요한 message rate와 error에 대한 metric을 포함합니다.</p>
</div>
<div class="paragraph">
<p>사전 구축된 application은 가장 널리 사용되는 두가지 모니터링 시스템인 Prometheus 및 InfluxDB를 지원하도록 구성됩니다.<br>
사용할 모니터링 시스템을 선언적으로 선택할 수 있습니다.</p>
</div>
<div class="paragraph">
<p>Data Flow는 stream 모니터링을 시작하는데 도움이 되도록 사용자 요구에 맞게 설치 및 customize할 수 있는 Grafana Dashboard를 제공합니다.</p>
</div>
<div class="paragraph">
<p>다음 그림은 application을 모니터링하는 일반적인 구조를 보여줍니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/micrometer-arch.webp" alt="micrometer arch">
</div>
</div>
<div class="paragraph">
<p>다음 이미지는 time | filter | log DSL 표현식으로 정의된 두 개의 스트림 생성을 보여줍니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/monitoring-stream-defs.webp" alt="monitoring stream defs">
</div>
</div>
<div class="paragraph">
<p>다음 그림은 Grafana의 대시 보드를 보여줍니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/grafana-dashboard.webp" alt="grafana dashboard">
</div>
</div>
<div class="paragraph">
<p>Stream Monitoring Feature Guide에 모니터링 인프라를 설정하는 방법에 대한 자세한 정보가 포함되어 있습니다.</p>
</div>
</div>
<div class="sect2">
<h3 id="tooling"><a class="anchor" href="#tooling"></a>1.5. Tooling</h3>
<div class="paragraph">
<p>Dashboard와 Shell은 Spring Cloud Data Flow와 상호 작용하는 주요 방법입니다.<br>
curl을 사용하여 RESTful API를 호출하거나 java client library를 사용하는 application을 작성한 다음 java client library가 RESTful API를 호출할 수도 있습니다.<br>
이 섹션에선느 dashboard 및 shell의 기능을 소개합니다.</p>
</div>
<div class="sect3">
<h4 id="dashboard"><a class="anchor" href="#dashboard"></a>1.5.1. Dashboard</h4>
<div class="paragraph">
<p>Spring Cloud Data Flow는 Dashboard라고 하는 브라우저 기반의 GUI를 제공하며 왼쪽에 있는 여러 탭에서 Data Flow의 기능을 구성합니다.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>App: 등록된 모든 application을 나열하고 새로운 application을 등록하거나 기존 application을 등록 취소할 수 있는 control을 제공합니다.</p>
</li>
<li>
<p>Runtime: 실행 중인 모든 application의 목록을 제공합니다.</p>
</li>
<li>
<p>Streams: Stream의 정의를 나열, 디자인, 생성, 배포 및 삭제할 수 있습니다.</p>
</li>
<li>
<p>Tasks: task의 정의를 나열, 작성, 실행, 예약 및 삭제 할 수 있습니다.</p>
</li>
<li>
<p>Jobs: Spring Batch Job의 실행 기록을 보고 작업 실행을 다시 시작할 수 있습니다.</p>
</li>
<li>
<p>Audit Records: 기록된 감사 이벤트에 접근합니다.</p>
</li>
<li>
<p>About: 지원 요청 및 설명서 링크 및 Data Flow Shell download에 사용할 release 정보를 제공합니다.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>다음 이미지는 정보 탭(및 dashboard UI의 일반적인  구조)를 보여줍니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/ui-about-tab.webp" alt="ui about tab">
</div>
</div>
</div>
<div class="sect3">
<h4 id="shell"><a class="anchor" href="#shell"></a>1.5.2. Shell</h4>
<div class="paragraph">
<p>Dashboard의 대안으로 Shell을 사용하여 Data Flow를 사용할 수 있습니다.<br>
Shell에는 이전 Dashboard 섹션에 나열된 대부분의 동일한 작업을 수행할 수 있는 명령이 있지만 audit 작업은 예외입니다.</p>
</div>
<div class="paragraph">
<p>Stream과 Batch DSL에 대한 탭 완성을 지원합니다.<br>
Shell을 Data Flow server에 연결하기 위한 command-line 옵션이 있습니다.</p>
</div>
<div class="paragraph">
<p>help로 command list를 확인할 수 있고 각 개별 명령에 대한 도움말은 help &lt;command&gt;로 확인할 수 있습니다.<br>
다음 이미지는 명령의 일부 목록을 보여줍니다.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="./images/shell-help.webp" alt="shell help">
</div>
</div>
</div>
<div class="sect3">
<h4 id="restful-api"><a class="anchor" href="#restful-api"></a>1.5.3. RESTful API</h4>
<div class="paragraph">
<p>Data Flow의 RESTful API는 HTTP 구문 사용시 표준 HTTP 및 REST 규칙에 최대한 가깝게 노력합니다.<br>
예를 들어 GET은 리소스를 검색하는데 사용되며 POST는 리소스를 생성하기 위해 사용됩니다.</p>
</div>
<div class="paragraph">
<p>Data Flow는 hypermedia를 사용하며 리소스의 응답에 다른 리소스에 대한 링크가 포함됩니다.<br>
Response are in the Hypertext Application from resource-to-resource language-HAL.<br>
_link 키 아래에서 링크를 찾을 수 있습니다.<br>
API 사용자는 URI 자체를 작성해서는 안됩니다. 대신 link를 사용하여 탐색해야 합니다.</p>
</div>
</div>
<div class="sect3">
<h4 id="java-client"><a class="anchor" href="#java-client"></a>1.5.4. Java Client</h4>
<div class="paragraph">
<p>Java Client 기능 가이드에는 프로그래밍 방식으로 Data Flow와 상호 작용하는 방법에 대한 자세한 정보가 들어있습니다.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="stream-developer-guides"><a class="anchor" href="#stream-developer-guides"></a>2. Stream Developer guides</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="developer-guides"><a class="anchor" href="#developer-guides"></a>2.1. Developer guides</h3>
<div class="paragraph">
<p>이 섹션에는 여러가지 가이드가 있지만 공통 시작 경로는 다음 단계로 구성됩니다.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>미리 작성된 applciation을 사용하여 Data Flow를 사용하며 stream을 만들고 배포하는 방법을 보여주는 시작 guide를 따릅니다.<br>
이를 통해 Dashboard를 사용하여 stream을 만들고 배포하고 로그를 보는 방벙을 빠르게 알 수 있습니다.</p>
</li>
<li>
<p>Spring Cloud Stream을 사용하여 source, processor 및 sink application을 직접 개발하고, 플랫폼에 수동으로 배포하고 RabbitMQ 및 Apache Kafka의 message broker에서 일어나는 일을 살펴보십시오.</p>
</li>
<li>
<p>개발한 source, processor, sink application을 사용하고 Data Flow를 사용하여 stream을 만들고 이를 플랫폼에 배포합니다.<br>
이러한 방식으로 완전히 수동 개발 및 배포 방식과 비교할 때 전체 개발 및 배포 work flow에서 Data Flow가 처리하는 부분을 보다 명확하게 파악할 수 있습니다.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="getting-started"><a class="anchor" href="#getting-started"></a>2.2. Getting Started</h3>
<div class="paragraph">
<p>이 섹션에서는 기존의 stream application으로 streaming data pipeline을 생성하고 Spring Cloud Data Flow를 사용하여 이를 배포하는 방법을 설명합니다.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a href="stream.html">Stream Processing</a> </dt>
<dd>
<p>local machine에 미리 작성된 application을 사용하여 streaming data pipeline 만들기 및 배포</p>
</dd>
</dl>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Version 2.2.0.RELEASE<br>
Last updated 2021-06-11 09:55:56 +0900
</div>
</div>
<link rel="stylesheet" href="js/highlight/styles/github.min.css">
<script src="js/highlight/highlight.min.js"></script>
<script>hljs.initHighlighting()</script>
<script type="text/javascript" src="js/tocbot/tocbot.min.js"></script>
<script type="text/javascript" src="js/toc.js"></script>
</body>
</html>